{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMeMBCrQb1Q6J1IijW5W2+o"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-_L2KwtOVyeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee81d0db-1553-4090-ac20-35ddc2fbbee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.11/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.32.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (3.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (4.13.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install scikit-learn\n",
        "!pip install nlpaug\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n"
      ],
      "metadata": {
        "id": "trz-FqsEV02c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/разметка_готовая.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "efCKPqalV4Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cf5d17-af46-4590-cc9c-8f3a57b44b67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1970 entries, 0 to 1969\n",
            "Data columns (total 6 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   comment                               1970 non-null   object \n",
            " 1   Нравится скорость отработки заявок    1970 non-null   int64  \n",
            " 2   Нравится качество выполнения заявки   1969 non-null   float64\n",
            " 3   Нравится качество работы сотрудников  1970 non-null   int64  \n",
            " 4   Понравилось выполнение заявки         1969 non-null   float64\n",
            " 5   Вопрос решен                          1967 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(1)\n",
            "memory usage: 92.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rbPz6-ymWXdB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_col = 'comment'\n",
        "label_cols = [\n",
        "    'Нравится скорость отработки заявок',\n",
        "    'Нравится качество выполнения заявки',\n",
        "    'Нравится качество работы сотрудников',\n",
        "    'Вопрос решен',\n",
        "    \"Понравилось выполнение заявки\"\n",
        "]\n",
        "df = df[[text_col] + label_cols].dropna()\n",
        "df = df[df[label_cols].sum(axis=1) > 0]"
      ],
      "metadata": {
        "id": "wh2qmAX5Y0qM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "def augment_texts(texts, augmenter, num_aug=3):\n",
        "    augmented_texts = []\n",
        "    for text in texts:\n",
        "        for _ in range(num_aug):\n",
        "            new_text = augmenter.augment(text)\n",
        "            augmented_texts.append(new_text)\n",
        "    return augmented_texts\n",
        "\n",
        "aug = naw.ContextualWordEmbsAug(\n",
        "    model_path='DeepPavlov/rubert-base-cased',\n",
        "    action=\"substitute\"\n",
        ")\n",
        "\n",
        "\n",
        "def augment_rare_classes(df, label_cols, target_count=100, augmenter=None, num_aug=3):\n",
        "    dfs = [df.copy()]\n",
        "\n",
        "    for label in label_cols:\n",
        "        df_label = df[df[label] == 1]\n",
        "        n_current = len(df_label)\n",
        "        n_to_add = target_count - n_current\n",
        "        if n_to_add <= 0:\n",
        "            continue\n",
        "\n",
        "        # Берём тексты и соответствующие метки\n",
        "        texts_to_augment = df_label['text'].tolist()\n",
        "        labels_to_copy = df_label[label_cols]\n",
        "\n",
        "        # Аугментируем\n",
        "        augmented_texts = []\n",
        "        augmented_labels = []\n",
        "\n",
        "        for idx, text in enumerate(texts_to_augment):\n",
        "            for _ in range(num_aug):\n",
        "                new_text = augmenter.augment(text)\n",
        "                augmented_texts.append(new_text)\n",
        "                augmented_labels.append(labels_to_copy.iloc[idx].values)\n",
        "\n",
        "                # Достаточно примеров? — прерываем\n",
        "                if len(augmented_texts) >= n_to_add:\n",
        "                    break\n",
        "            if len(augmented_texts) >= n_to_add:\n",
        "                break\n",
        "\n",
        "        # Формируем аугментированный датафрейм\n",
        "        augmented_df = pd.DataFrame(augmented_texts, columns=['text'])\n",
        "        for i, col in enumerate(label_cols):\n",
        "            augmented_df[col] = [label[i] for label in augmented_labels]\n",
        "\n",
        "        dfs.append(augmented_df)\n",
        "\n",
        "    # Объединяем и перемешиваем\n",
        "    return pd.concat(dfs).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df = augment_rare_classes(df, label_cols, target_count=100, augmenter=aug, num_aug=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dGOO0x3vBAE",
        "outputId": "6636a82a-a4dd-442d-d5fb-f3ed61c538f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[label_cols].sum()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "3gAZKnk4tsMb",
        "outputId": "2b8e77b9-0892-45ae-e37f-1d6c9ba7a68f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Нравится скорость отработки заявок       808.0\n",
              "Нравится качество выполнения заявки      150.0\n",
              "Нравится качество работы сотрудников     228.0\n",
              "Вопрос решен                            1267.0\n",
              "Понравилось выполнение заявки            271.0\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Нравится скорость отработки заявок</th>\n",
              "      <td>808.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Нравится качество выполнения заявки</th>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Нравится качество работы сотрудников</th>\n",
              "      <td>228.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Вопрос решен</th>\n",
              "      <td>1267.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Понравилось выполнение заявки</th>\n",
              "      <td>271.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "IZkRhoELY8Qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fbc4cb-f146-4550-fb9d-45c52fdbcafa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1671 entries, 0 to 1670\n",
            "Data columns (total 6 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   comment                               1671 non-null   object \n",
            " 1   Нравится скорость отработки заявок    1671 non-null   int64  \n",
            " 2   Нравится качество выполнения заявки   1671 non-null   float64\n",
            " 3   Нравится качество работы сотрудников  1671 non-null   int64  \n",
            " 4   Вопрос решен                          1671 non-null   float64\n",
            " 5   Понравилось выполнение заявки         1671 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(1)\n",
            "memory usage: 78.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X = df['comment'].values\n",
        "y = df[label_cols].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "dFVQ4mJ5Z4IJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "class CommentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = tokenizer(self.texts[idx],\n",
        "                             truncation=True,\n",
        "                             padding='max_length',\n",
        "                             max_length=128,\n",
        "                             return_tensors=\"pt\")\n",
        "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "train_dataset = CommentDataset(X_train, y_train)\n",
        "test_dataset = CommentDataset(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "1D93bEwZZ7TN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "label_counts = np.sum(y_train, axis=0)\n",
        "total_counts = y_train.shape[0]\n",
        "\n",
        "pos_weights = total_counts / (label_counts + 1e-6)\n",
        "pos_weights = torch.tensor(pos_weights, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "pE_Y72RSylZ6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, pos_weight, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.pos_weight = pos_weight.to(self.args.device)  # переводим веса на нужное устройство\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "\n",
        "        # Переводим labels на то же устройство, что и модель\n",
        "        labels = labels.to(model.device)\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fn(logits, labels.float())\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n"
      ],
      "metadata": {
        "id": "L9uBGNSAq_bw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\",\n",
        "    num_labels=len(label_cols),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=8,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    #evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    pos_weight=pos_weights,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "ZZzE1iiAaEjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "0ef04c91-b989-4bd4-a685-b1c9e069520f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-11-28f5e88fa894>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1336' max='1336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1336/1336 06:14, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.997200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.816400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.715900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.565600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.466100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.446200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.365600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.370800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.306100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.207100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.225700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1336, training_loss=0.5095037875061263, metrics={'train_runtime': 375.8515, 'train_samples_per_second': 28.437, 'train_steps_per_second': 3.555, 'total_flos': 703051676663808.0, 'train_loss': 0.5095037875061263, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "preds= trainer.predict(test_dataset)\n",
        "\n",
        "y_pred = (preds.predictions > 0.5).astype(int)\n",
        "y_true = np.asarray(y_test).astype(int)\n",
        "\n",
        "# Заменим 2 → 1\n",
        "y_true[y_true == 2] = 1\n",
        "\n",
        "print(\"Unique values in y_true (after fix):\", np.unique(y_true))\n",
        "print(classification_report(y_true, y_pred, target_names=label_cols))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f7taGiCUaFOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "d4623533-a90d-4f36-ac60-06c9329fe3ba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_true (after fix): [0 1]\n",
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "  Нравится скорость отработки заявок       0.96      0.95      0.96       168\n",
            " Нравится качество выполнения заявки       0.82      0.66      0.73        35\n",
            "Нравится качество работы сотрудников       0.62      0.52      0.57        48\n",
            "                        Вопрос решен       0.96      0.97      0.96       243\n",
            "       Понравилось выполнение заявки       0.58      0.62      0.60        52\n",
            "\n",
            "                           micro avg       0.89      0.87      0.88       546\n",
            "                           macro avg       0.79      0.74      0.76       546\n",
            "                        weighted avg       0.88      0.87      0.88       546\n",
            "                         samples avg       0.91      0.90      0.89       546\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "                 precision    recall  f1-score   support\n",
        "\n",
        "  Нравится скорость отработки заявок       0.94      0.97      0.96       153\n",
        " Нравится качество выполнения заявки       0.81      0.54      0.65        24\n",
        "Нравится качество работы сотрудников       0.65      0.59      0.62        51\n",
        "                        Вопрос решен       0.98      0.96      0.97       257\n",
        "       Понравилось выполнение заявки       0.69      0.49      0.57        49\n",
        "\n",
        "                           micro avg       0.91      0.87      0.89       534\n",
        "                           macro avg       0.82      0.71      0.75       534\n",
        "                        weighted avg       0.91      0.87      0.88       534\n",
        "                         samples avg       0.93      0.90      0.90       534\n",
        "                         \n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nbnimzRq1rSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# preds.predictions — это логиты, подаём их как вероятности\n",
        "# y_true — бинарные истинные метки (после исправлений)\n",
        "# y_pred_proba — вероятности принадлежности к классу (до округления)\n",
        "\n",
        "y_pred_proba = preds.predictions\n",
        "y_true = np.asarray(y_test).astype(int)\n",
        "y_true[y_true == 2] = 1  # На всякий случай ещё раз\n",
        "\n",
        "# ROC-AUC по каждому классу\n",
        "roc_auc_per_class = roc_auc_score(y_true, y_pred_proba, average=None)\n",
        "\n",
        "# Средние оценки\n",
        "roc_auc_macro = roc_auc_score(y_true, y_pred_proba, average=\"macro\")\n",
        "roc_auc_micro = roc_auc_score(y_true, y_pred_proba, average=\"micro\")\n",
        "roc_auc_weighted = roc_auc_score(y_true, y_pred_proba, average=\"weighted\")\n",
        "\n",
        "# Выводим\n",
        "print(\"ROC-AUC по каждому классу:\")\n",
        "for label, score in zip(label_cols, roc_auc_per_class):\n",
        "    print(f\"{label}: {score:.3f}\")\n",
        "\n",
        "print(\"\\nROC-AUC (macro):\", round(roc_auc_macro, 3))\n",
        "print(\"ROC-AUC (micro):\", round(roc_auc_micro, 3))\n",
        "print(\"ROC-AUC (weighted):\", round(roc_auc_weighted, 3))\n"
      ],
      "metadata": {
        "id": "LPif8IwMePL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0b83aa-9d27-4e3c-a100-6c1836c92c95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC по каждому классу:\n",
            "Нравится скорость отработки заявок: 0.984\n",
            "Нравится качество выполнения заявки: 0.892\n",
            "Нравится качество работы сотрудников: 0.801\n",
            "Вопрос решен: 0.960\n",
            "Понравилось выполнение заявки: 0.849\n",
            "\n",
            "ROC-AUC (macro): 0.897\n",
            "ROC-AUC (micro): 0.946\n",
            "ROC-AUC (weighted): 0.938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "ROC-AUC по каждому классу:\n",
        "Нравится скорость отработки заявок: 0.984\n",
        "Нравится качество выполнения заявки: 0.892\n",
        "Нравится качество работы сотрудников: 0.801\n",
        "Вопрос решен: 0.960\n",
        "Понравилось выполнение заявки: 0.849\n",
        "\n",
        "ROC-AUC (macro): 0.897\n",
        "ROC-AUC (micro): 0.946\n",
        "ROC-AUC (weighted): 0.938\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "mrlhBAX4qXGB"
      }
    }
  ]
}